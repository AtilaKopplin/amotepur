[
["visao-geral-da-amostragem-e-estimacao.html", "Capítulo 3 Visão Geral da Amostragem e Estimação 3.1 Definições e Notação para População de Pesquisa e Parâmetros Selecionados 3.2 Amostra 3.3 Amostragem Probabilística 3.4 Estatísticas, Estimadores e Estimativas 3.5 A Distribuição de Aleatorização 3.6 Estimadores Não Viciados para o Total 3.7 Teoria Básica", " Capítulo 3 Visão Geral da Amostragem e Estimação 3.1 Definições e Notação para População de Pesquisa e Parâmetros Selecionados Nesta seção introduzimos algumas definições e notação necessárias para a apresentação da teoria da amostragem ao longo do texto. Chama-se população (daqui por diante, esta é a designação da população de pesquisa que será objeto do levantamento de dados) qualquer conjunto contendo um número finito \\(N\\) de unidades, delimitada por compartilharem de algumas características em comum. As unidades deste conjunto serão denominadas unidades da população. Representaremos nosso cadastro dessa população por um conjunto de \\(N\\) rótulos distintos denominado \\(U=\\{1,2,\\dots,i,\\dots,N\\}\\), sendo: \\(N\\) o tamanho da população e \\(i\\) o rótulo para uma unidade genérica da população. Cada unidade da população fica devidamente identificada por seu rótulo no conjunto \\(U\\). São exemplos comuns de populações sobre as quais se realizam pesquisas: domicílios e moradores de certa localidade; indústrias instaladas num certo país; fazendas situadas num certo estado; alunos da rede escolar estadual, etc.. Já foi enfatizada no capítulo anterior a importância de uma definição clara e precisa da população de pesquisa. No entanto, ao estudar Amostragem, o maior interesse está voltado para o problema de estimar ou inferir certas quantidades ou parâmetros de diversas características (variáveis) numéricas que podem ser medidas ou observadas para cada unidade da população. No caso de características ou variáveis categóricas, podem ser criadas variáveis numéricas indicadoras das categorias de resposta, tomando valor igual a um se a unidade é classificada na categoria em questão, e valor igual a zero caso contrário. Desta forma, toda a teoria de amostragem se resume à estimação de parâmetros ou quantidades descritivas de variáveis numéricas que poderiam, em tese, ser medidas para todas as unidades da população de pesquisa. De fato, cada característica numérica ou variável de interesse dá origem a um vetor populacional, que é o conjunto de valores da variável correspondentes a cada uma das unidades da população. Por exemplo, se \\(y\\) é a variável de pesquisa / de interesse e \\(y_i\\) é o valor da variável \\(y\\) para a unidade \\(i\\), então \\(Y_U=\\{y_1,y_2,\\dots,y_i,\\dots,y_N\\}\\) é o vetor populacional gerado pela variável \\(y\\). Pelo exposto, deve ficar claro que a observação de várias variáveis de uma mesma população vai gerar diversos vetores populacionais, cada um correspondendo a uma das variáveis observadas. Em muitos casos, o interesse em estudar determinada população resume-se à necessidade de conhecer os valores de alguns parâmetros de uma ou mais variáveis que podem ser medidas ou observadas para unidades daquela população. Esses parâmetros-alvo (ou de interesse) podem ser quaisquer funções dos valores dos vetores populacionais. Os casos mais comuns ocorrem quando há interesse em estimar totais, médias, proporções, razões, quantis ou mesmo variâncias, covariâncias e correlações, sendo raros os casos de interesse por outros parâmetros. Os principais parâmetros de interesse podem ser representados por meio das seguintes funções dos valores de variáveis na população. \\(Y=\\displaystyle\\sum_{i=1}^{N}y_i=\\sum_{i\\in U}y_i\\quad\\) o total populacional da variável \\(y\\). \\(\\overline{Y} = \\displaystyle \\frac{Y}{N}= \\frac{1}{N}\\sum_{i\\in U} y_i \\quad\\) a média populacional da variável \\(y\\). Uma proporção populacional \\(p\\) é simplesmente a média populacional de uma variável \\(y\\) do tipo indicadora, que toma apenas os valores um ou zero para cada unidade. O total de uma variável desse tipo representa a contagem de unidades na população possuidoras do atributo de interesse, e a média é exatamente essa contagem dividida pelo tamanho da população. Um caso especial de proporção populacional de interesse ocorre com a definição da função de distribuição cumulativa empírica populacional (FDCEP), dada por: \\(F_U(t)= \\frac{1}{N} \\displaystyle \\sum_{i\\in U} I(y_i \\le t) \\quad\\), onde \\(t \\in \\rm{I\\!R\\!}\\). Esta função retorna a proporção de valores de \\(y\\) na população \\(U\\) que têm valor menor ou igual a \\(t\\). O quantil populacional \\(q\\) da distribuição da variável \\(y\\) é definido como o menor valor de \\(y\\) tal que a FDCEP tem valor maior ou igual a \\(q\\), isto é: \\(T_U(q)= argmin\\{F_U(t) \\ge q\\} \\quad\\). Por exemplo, a mediana populacional da variável \\(y\\) corresponde ao quantil obtido quando \\(q=0,5\\), isto é, \\(Mediana_U = T_U(0,5)\\). \\(S^2_y=\\displaystyle\\frac{1}{N-1}\\sum_{i\\in U}({y_i-\\overline{Y}})^2=\\frac{1}{N-1}\\left[\\sum_{i\\in U}{y_i}^2-N\\overline{Y}^2\\right]\\quad\\) a variância populacional da variável \\(y\\). Seja \\(z\\) outra variável de pesquisa, tomando valores \\(z_i\\), \\(i\\in U\\). Define-se então a razão de totais das variáveis \\(y\\) e \\(z\\) como: \\(R={\\frac{\\displaystyle\\sum_{i\\in U}y_i}{\\displaystyle\\sum_{i\\in U}z_i}}\\quad\\). Define-se também a covariância populacional e a correlação populacional das variáveis \\(y\\) e \\(z\\) como: \\(S_{yz}=\\displaystyle\\frac{1}{N-1}\\sum_{i\\in U}({y_i-\\overline{Y}})({z_i-\\overline{Z}})=\\frac{1}{N-1}\\left[\\sum_{i\\in U}{y_i}{z_i}-N\\,\\overline{Y}\\,\\overline{Z}\\right]\\quad\\) e \\({\\rho}_{yz}=\\frac{S_{yz}}{S_y S_z}\\quad\\). Até agora foram apresentadas as definições de alguns parâmetros da população que se deseja conhecer. No entanto, para conhecer exatamente o valor de qualquer dos parâmetros definidos, seria necessário conhecer todos os valores daquela população. Isto só seria possível mediante a realização de um Censo no qual a variável fosse medida ou observada para cada uma das unidades da população. Por outro lado, pode ser que estimativas desses parâmetros, com margens de erro conhecidas e controladas, sirvam para os propósitos dos interessados. Neste caso, uma pesquisa por amostragem poderia resolver o problema com vantagens em relação a um Censo. Entre as vantagens mais diretas de pesquisas por amostragem podem ser mencionados os menores custos de obtenção das informações de interesse, a maior rapidez para obtenção dos resultados, e a redução da carga de coleta de informações sobre a população de pesquisa. De agora em diante, admitir-se-á sempre que a situação enfrentada é tal que basta conhecer estimativas dos parâmetros de interesse, bem como indicações da margem de erro a que tais estimativas estão sujeitas. A seguir, tomando por base a ideia de obter estimativas dos parâmetros de interesse, serão apresentados os principais conceitos relacionados com a amostragem de populações finitas. 3.2 Amostra Uma amostra \\(s=\\{i_1, i_2, \\dots, i_n\\}\\) é qualquer subconjunto não vazio de unidades selecionadas da população \\(U (s \\subset U)\\) para observação visando estimar os parâmetros de interesse. Uma amostra de tamanho \\(n\\) é uma amostra contendo \\(n\\) unidades selecionadas da população \\(U\\), sendo \\(1 \\leq n \\leq N\\). A notação \\(i \\in s\\) designa que a unidade \\(i\\) foi incluída na amostra \\(s\\). A notação \\(s \\ni i\\) indica o conjunto de amostras \\(s\\) que contém a unidade \\(i\\). No contexto deste livro, apresentaremos somente a teoria e resultados aplicáveis a amostras probabilísticas, isto é, a amostras selecionadas com base em regras de aleatorização bem definidas e que satisfazem as condições 1 a 3 enunciadas na seção ??, e descritas de maneira mais formal na próxima seção. Os dados amostrais para a variável \\(y\\) serão representados por \\(\\{y_{i_1}, y_{i_2}, \\dots, y_{i_n}\\}\\). 3.3 Amostragem Probabilística A amostragem probabilística é qualquer procedimento de amostragem que satisfaça todas as condições enumeradas a seguir: O espaço amostral \\(S\\), correspondente ao conjunto de todas as amostras \\(s\\) possíveis, é bem definido, e poderia ser enumerado, ao menos teoricamente. Uma probabilidade \\(p(s)\\) conhecida (ou calculável) é associada a cada amostra \\(s \\in S\\), de tal modo que \\(\\displaystyle \\sum_{s \\in S} p(s) = 1\\). A função \\(p(s)\\) é denominada plano amostral. Uma única amostra \\(s\\) \\((s \\in S)\\) é selecionada para observação usando um mecanismo de aleatorização (sorteio) tal que a amostra \\(s\\) é escolhida com probabilidade igual a \\(p(s)\\). Cada unidade \\(i \\in U\\) tem uma probabilidade positiva de ser selecionada para a amostra, isto é: $i = P(i s) = {s i} p(s) &gt; 0 $ \\(\\forall i \\in U\\). A probabilidade \\(\\pi_i\\) é denominada probabilidade de inclusão (de primeira ordem) da unidade \\(i\\). As probabilidades de inclusão das unidades selecionadas para a amostra e outros aspectos da estrutura do plano amostral são levadas em conta ao fazer inferência sobre os parâmetros populacionais. 3.4 Estatísticas, Estimadores e Estimativas Uma estatística é uma função real dos valores observados numa amostra da população, isto é, é qualquer função real \\(f( y_{i_1}, y_{i_2}, \\dots, y_{i_n} )\\). Considere os dois exemplos a seguir: \\(t(s) = t = \\displaystyle \\sum_{i \\in s} y_i \\quad\\) é o total amostral ou soma amostral da variável \\(y\\); e \\(\\overline{y} = \\displaystyle \\frac{t(s)}{n} = \\frac{1}{n} \\sum_{i \\in s} y_i \\quad\\) é a média amostral da variável \\(y\\). Um estimador \\(\\hat{\\theta}(s)\\) é uma estatística usada para estimar um certo parâmetro \\(\\theta\\) de interesse. Antes de observarmos a amostra \\(s\\), um estimador é uma variável aleatória cuja distribuição temos interesse de conhecer, pois dela dependem propriedades importantes do estimador. Por simplicidade, daqui para a frente vamos usar a notação \\(\\hat{\\theta}\\) para designar estimadores, sem explicitar sua dependência da determinação da amostra \\(s\\), sempre que isso for possível. Após a determinação da amostra \\(s\\) e a coleta dos dados das unidades nessa amostra, o valor calculado (observado) do estimador é chamado de estimativa do parâmetro. Uma questão central da teoria da amostragem é como escolher bons estimadores para os parâmetros de interesse. Intuitivamente, bons estimadores seriam estatísticas cujos valores fiquem próximos do valor do parâmetro que buscam estimar. Para ajudar com essa questão, é essencial dispor de critérios para a escolha de estimadores. Mas antes disso, é útil definir algumas propriedades de estimadores que serão consideradas na elaboração de critérios de decisão ou escolha que vamos propor usar. O valor esperado de um estimador \\(\\hat{\\theta}\\) é denotado por \\(E_p(\\hat{\\theta})\\). A notação \\(E_p(\\bullet)\\) designa o valor esperado da quantidade sob a distribuição de probabilidades induzida pelo plano amostral, isto é: \\(E_p(\\hat{\\theta}) = \\displaystyle \\sum_{s\\in S} \\hat{\\theta}(s) p(s) \\quad\\) O vício (ou viés ou tendência) do estimador \\(\\hat{\\theta}\\) é definido como: \\(B_p(\\hat{\\theta}) = E_p(\\hat{\\theta}) - \\theta\\). Algumas vezes é de interesse expressar o vício em termos relativos, e se utiliza então o vício relativo do estimador, definido como: \\(RB_p(\\hat{\\theta}) = \\frac{B_p(\\hat{\\theta})}{\\theta}\\). Vício é uma característica indesejada num estimador, pois significa que a distribuição do estimador \\(\\hat{\\theta}\\) não é centrada no alvo de inferência \\(\\theta\\). Diz-se que o estimador \\(\\hat{\\theta}\\) é não viciado (ou não viesado ou não tendencioso) para o parâmetro \\(\\theta\\) quando seu valor esperado é igual ao parâmetro \\(\\theta\\), isto é, quando \\(E_p(\\hat{\\theta})= \\theta\\), ou alternativamente, quando \\(B_p(\\hat{\\theta}) = RB_p(\\hat{\\theta}) = 0\\). Nosso primeiro critério para apoiar a escolha de estimadores sugere então que tratemos de usar estimadores sem vício, ou não viciados, ou ao menos aproximadamente não viciados. Quando isto for possível, teremos estimadores cuja distribuição será centrada no alvo desejado da inferência. A variância do estimador \\(\\hat{\\theta}\\) é definida como: \\(V_p(\\hat{\\theta}) = \\displaystyle \\sum_{s \\in S} [\\hat{\\theta}(s) - E_p(\\hat{\\theta})]^2 p(s) \\quad\\) Quando um estimador é não viciado, sua variância mede a dispersão da distribuição do estimador em torno do alvo de inferência \\(\\theta\\). Duas medidas alternativas dessa dispersão que dependem da variância são o desvio padrão ou DP do estimador (também designado erro padrão), dado por \\(DP_p(\\hat{\\theta}) = [V_p(\\hat{\\theta})]^{1/2} \\quad\\) e o coeficiente de variação ou CV do estimador, dado por: \\(CV_p(\\hat{\\theta}) = \\frac{DP_p(\\hat{\\theta})}{\\theta} \\quad\\). O desvio padrão mede a dispersão da distribuição do estimador em unidade de medida igual à usada na mensuração do parâmetro de interesse, e o CV expressa essa medida em termos relativos, o que pode facilitar a interpretação e a comparação em cenários onde as unidades de medida de diferentes parâmetros podem ser distintas, mas exista interesse em comparar dispersão de estimadores desses parâmetros. Quando um estimador \\(\\hat{\\theta}\\) é viciado, uma medida mais adequada da dispersão da distribuição do estimador em torno do alvo de inferência \\(\\theta\\) é o erro quadrático médio ou EQM dado por: \\(EQM_p(\\hat{\\theta}) = \\displaystyle \\sum_{s\\in S} [\\hat{\\theta}(s) - \\theta]^2 p(s) \\quad\\). Versões análogas do desvio padrão e do coeficiente de variação adequadas ao caso de estimadores viciados são o erro médio ou EM e o erro relativo médio ou ERM definidos como \\(EM_p(\\hat{\\theta}) = [EQM_p(\\hat{\\theta})]^{1/2} \\quad\\) e \\(ERM_p(\\hat{\\theta}) = \\frac{EM_p(\\hat{\\theta})}{\\theta} \\quad\\) respectivamente. Um mesmo parâmetro pode ter mais de um estimador não viciado disponível. Precisamos então de um segundo critério para ajudar na escolha de estimadores. Nosso segundo critério vai usar a variância, no caso de estimadores exatamente não viciados, ou o EQM nos outros casos. Como se quer ter estimadores com os menores erros de estimação, o segundo critério é o de escolher sempre os estimadores com a menor variância (ou menor EQM). No contexto da Amostragem, diferente do contexto usual da Inferência Estatística, não se estabelece uma distribuição de probabilidade (ou modelo) para os valores da variável \\(y\\) na amostra (ou na população). Além disso, em geral os parâmetros que se deseja estimar não são responsáveis pela especificação de uma tal distribuição de probabilidades (ou modelo). Como já indicado, em geral os parâmetros de interesse são definidos como funções dos valores (fixos mas desconhecidos) da variável \\(y\\) na população. Por esse motivo, na Amostragem de populações finitas, não há um procedimento geral para gerar estimadores que sejam ótimos nalgum sentido, como é o caso do método da máxima verossimilhança no contexto usual da Inferência Estatística. Os princípios usados em Amostragem para derivar estimadores dos parâmetros de interesse são baseados na simplicidade e no método dos momentos, como vamos ilustrar. Suponha que o parâmetro-alvo é o total populacional \\(Y\\). Nesse caso, o objetivo principal seria usar os dados amostrais \\(\\{y_{i_1}, y_{i_2}, \\dots, y_{i_n}\\}\\) para estimar \\(Y = \\displaystyle \\sum_{i \\in U} y_i\\). Um segundo objetivo seria conseguir medir ou estimar também a precisão ou a margem de erro da estimativa produzida para \\(Y\\). Um estimador linear \\(\\hat{Y_w}\\) do total populacional \\(Y\\) é uma combinação linear dos valores amostrais \\(y_i\\) com pesos amostrais \\(w_i\\) a serem definidos, isto é: \\(\\hat{Y_w} = \\displaystyle \\sum_{i \\in s} {w_i}{y_i}\\) Podemos então usar os critérios sugeridos para escolha de estimadores para determinar os pesos \\(w_i\\), como veremos mais adiante no texto. Para ajudar a consolidar as ideias já apresentadas até aqui, faremos agora uso de um exemplo muito simples, mas através do qual poderemos ilustrar como operar com os conceitos e definições já introduzidos. Exemplo 2.1: Considere os dados de uma população fictícia com \\((N=4)\\) mulheres (unidades elementares), de quem foi indagado o número de filhos tidos vivos (a nossa variável \\(y\\)). \\[\\begin{array}{|l|c|c|c|c|c|}\\hline \\textrm{Rótulo da unidade}\\,\\, i &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; \\textrm{Total} \\\\\\hline \\textrm{Valor de}\\,\\, y_i &amp; 0 &amp; 0 &amp; 2 &amp; 1 &amp; 3\\\\\\hline \\end{array}\\] Existem \\(\\binom{4}{2}= 6\\) amostras possíveis de tamanho \\(n=2\\). \\(S = \\{(1;2); (1;3); (1;4); (2;3); (2;4); (3;4)\\}\\quad\\) é o conjunto de todas as amostras possíveis. A notação para representar o conjunto que forma cada amostra foi o ( ), para evitar usar { } dentro de { }. Cada elemento do conjunto S é em si mesmo um conjunto de rótulos de unidades selecionadas para a amostra. As amostras são selecionadas com igual probabilidade. Cada amostra tem probabilidade de ser selecionada igual a 1/6 \\(\\rightarrow p(s)=1/6 \\,\\,\\,\\forall s\\in S\\). A tabela, a seguir, apresenta o conjunto de todas as amostras possíveis, as unidades de cada amostra, os valores de \\(y\\) na amostra, a soma amostral e as probabilidades de cada amostra ser selecionada. \\[\\begin{array}{|c|c|c|c|c|}\\hline \\textrm {Amostra} \\,\\,s &amp; \\textrm{Unidades na Amostra} &amp; \\textrm{Valores na Amostra} &amp; \\textrm {Soma Amostral}\\,\\, (t) &amp; \\textrm{Probablidades} \\,\\, p(s)\\\\\\hline 1 &amp; \\textrm{{1;2}} &amp; \\textrm{{0;0}} &amp; 0 &amp; 1/6\\\\\\hline 2 &amp; \\textrm{{1;3}} &amp; \\textrm{{0;2}} &amp; 2 &amp; 1/6\\\\\\hline 3 &amp; \\textrm{{1;4}} &amp; \\textrm{{0;1}} &amp; 1 &amp; 1/6\\\\\\hline 4 &amp; \\textrm{{2;3}} &amp; \\textrm{{0;2}} &amp; 2 &amp; 1/6\\\\\\hline 5 &amp; \\textrm{{2;4}} &amp; \\textrm{{0;1}} &amp; 1 &amp; 1/6\\\\\\hline 6 &amp; \\textrm{{3;4}} &amp; \\textrm{{2;1}} &amp; 3 &amp; 1/6\\\\\\hline \\textrm{Total} &amp; \\textrm{-} &amp; \\textrm{-} &amp; 9 &amp; 1\\\\\\hline \\end{array}\\] A distribuição da Soma Amostral é dada por: \\[\\begin{array}{|l|c|c|c|c|}\\hline \\textrm{Valores possíveis de }\\,\\, t&amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\\\hline \\textrm{Com probabilidade}\\,\\, p(s) &amp; 1/6 &amp; 2/6 &amp; 2/6 &amp; 1/6\\\\\\hline \\end{array}\\] O valor esperado de \\(t\\) é: \\(E(t)= \\displaystyle\\sum_{s\\in S}t(s) p(s) = 0\\times\\frac{1}{6}+1\\times\\frac{2}{6}+2\\times\\frac{2}{6}+3\\times\\frac{1}{6}= \\frac{9}{6} = 1,5\\) Porém o total populacional é: \\(Y=\\displaystyle\\sum_{i=1}^{4}y_i= 3\\) Como \\(1,5= E(t) \\neq Y=3\\) , dizemos que \\(t\\) é um estimador viciado (ou enviesado) de \\(Y\\) sob o plano amostral \\(p(s)\\) adotado. Como podemos “corrigir” o estimador de modo que fique não viciado (não enviesado)? Resposta: multiplicando por 2 o valor da soma amostral t. Considere um novo estimador do total populacional: \\(\\hat{Y}= 2\\times t\\) Tal estimador na forma linear pode ser escrito como: \\(\\hat{Y}= 2\\times t =\\displaystyle\\sum_{i\\in S}2\\times y_i= \\hat{Y_w}\\) \\[\\begin{array}{|l|c|c|c|c|}\\hline \\textrm{Valores possíveis de }\\,\\, 2\\times t&amp; 0 &amp; 2 &amp; 4 &amp; 6\\\\\\hline \\textrm{Com probabilidade}\\,\\, p(s) &amp; 1/6 &amp; 2/6 &amp; 2/6 &amp; 1/6\\\\\\hline \\end{array}\\] O valor esperado de \\(\\hat{Y}= 2\\times t\\) é: \\(E(\\hat{Y})= \\displaystyle\\sum_{s\\in S}\\hat{Y_s} p(s) = 0\\times\\frac{1}{6}+2\\times\\frac{2}{6}+4\\times\\frac{2}{6}+6\\times\\frac{1}{6}= \\frac{18}{6} = 3\\) Como \\(E(\\hat{Y})=3=Y\\), dizemos que \\(\\hat{Y}= 2\\times t\\) é um estimador não viciado de \\(Y\\) sob o plano amostral \\(p(s)\\) adotado. 3.5 A Distribuição de Aleatorização A função \\(p(s)\\) definida no conjunto \\(S\\) de todas as amostras possíveis é uma distribuição de probabilidades. A distribuição de probabilidades \\(p(s)\\), \\(s \\in S\\), é chamada distribuição de aleatorização. Na amostragem probabilística, inferências são feitas considerando a distribuição de aleatorização. Tais inferências são baseadas no plano amostral, onde a fonte de variação ou incerteza é a repetição hipotética do processo de amostragem utilizando \\(p(s\\)), que resultaria em diferentes amostras \\(s_1, s_2, ... \\in S\\). A distribuição de \\(\\hat{Y}= 2\\times t=\\displaystyle\\sum_{i\\in S}2\\times y_i= \\hat{Y_w}\\) determinada por \\(p(s)\\) é chamada de distribuição amostral do estimador. Vamos estudar suas propriedades para avaliar se \\(\\hat{Y}\\) é um bom estimador para o total populacional Y. 3.6 Estimadores Não Viciados para o Total Obtenção de Estimadores Não Viciados para o Total Trabalhar com a distribuição \\(p(s)\\) é complicado. O número total de amostras possíveis cresce muito rapidamente com \\(N\\) e com \\(n\\). Por exemplo, o número de amostras sem reposição de tamanho \\(n\\) de uma população com \\(N\\) unidades é \\(\\binom{N}{n}\\) . A saída é usar propriedades simplificadoras desta distribuição. Uma Propriedade Importante A probabilidade de inclusão da unidade \\(i\\) na amostra é dada por: \\(P({i\\in s})=\\pi_i=\\displaystyle\\sum_{s\\ni i} p(s)\\) Se tomarmos o inverso da probabilidade de inclusão \\(\\frac{1}{\\pi_i}\\) como peso \\((w_i)\\) de uma unidade amostrada, é fácil verificar que o estimador é dado por: \\(\\hat{Y_w} =\\displaystyle\\sum_{i\\in s} w_iy_i= \\displaystyle\\sum_{i\\in s} \\frac{1}{\\pi_i}y_i=\\displaystyle\\sum_{i\\in s} {\\pi_i}^{-1}y_i\\quad\\) é não viciado para o total populacional \\(Y\\). Em continuidade do exemplo 2.1 da população de 4 unidades \\((N=4)\\) mulheres, de quem foi indagado o número de filhos tidos vivos (\\(y\\)), tem-se: \\[\\begin{array}{|l|c|c|c|c|c|}\\hline \\textrm{Rótulo da unidade}\\,\\, i &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; \\textrm{Total} \\\\\\hline \\textrm{Valor}\\,\\, y_i &amp; 0 &amp; 0 &amp; 2 &amp; 1 &amp; 3\\\\\\hline \\textrm {Probabilidade de inclusão}\\,\\, \\pi_i &amp; 3/6=1/2 &amp; 3/6=1/2 &amp; 3/6=1/2 &amp; 3/6=1/2 &amp; \\textrm{-}\\\\\\hline \\end{array}\\] Os pesos amostrais no exemplo 2.1 são \\(w_i = \\frac{1}{\\pi_i} = \\frac{1}{1/2} = 2\\) O estimador ponderado do total é dado por: \\(\\hat{Y_w} =\\displaystyle\\sum_{i\\in s} w_iy_i= \\displaystyle\\sum_{i\\in s} {\\pi_i}^{-1}y_i = \\displaystyle\\sum_{i\\in s} 2y_i=2t\\) E já se mostrou que este estimador é não viciado para \\(Y\\). Exemplo 2.2 Considere a mesma população fictícia do exemplo 2.1. Considere agora o plano amostral que retira amostras de tamanho 2 dessa população segundo o plano amostral dado na tabela a seguir. \\[\\begin{array}{|c|c|c|c|c|}\\hline \\textrm {Amostra} \\,\\,s &amp; \\textrm{Unidades na Amostra} &amp; \\textrm{Valores na Amostra} &amp; \\textrm {Soma Amostral}\\,\\, (t) &amp; \\textrm{Probablidades} \\,\\, p(s)\\\\\\hline 1 &amp; \\textrm{{1;2}} &amp; \\textrm{{0;0}} &amp; 0 &amp; 0,00\\\\\\hline 2 &amp; \\textrm{{1;3}} &amp; \\textrm{{0;2}} &amp; 2 &amp; 0,20\\\\\\hline 3 &amp; \\textrm{{1;4}} &amp; \\textrm{{0;1}} &amp; 1 &amp; 0,15\\\\\\hline 4 &amp; \\textrm{{2;3}} &amp; \\textrm{{0;2}} &amp; 2 &amp; 0,20\\\\\\hline 5 &amp; \\textrm{{2;4}} &amp; \\textrm{{0;1}} &amp; 1 &amp; 0,15\\\\\\hline 6 &amp; \\textrm{{3;4}} &amp; \\textrm{{2;1}} &amp; 3 &amp; 0,30\\\\\\hline \\textrm{Total} &amp; \\textrm{-} &amp; \\textrm{-} &amp; 9 &amp; 1,00\\\\\\hline \\end{array}\\] Chamaremos este plano amostral de plano 2. Use as informações acima para: Verificar que o estimador baseado na soma amostral (\\(t\\)) é viciado para estimar o total populacional \\(Y\\); Obter / definir um estimador não viciado para o total populacional \\(Y\\); Comente sobre o uso de um plano amostral em que as diferentes amostras têm probabilidades desiguais de serem selecionadas. Surpresas? Dificuldades? A distribuição do Total Amostral sob plano 2 é dada por: \\[\\begin{array}{|l|c|c|c|c|}\\hline \\textrm{Valores possíveis de }\\,\\, t&amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\\\hline \\textrm{Com probabilidade}\\,\\, p(s) &amp; 0,0 &amp; 0,3 &amp; 0,4 &amp; 0,3\\\\\\hline \\end{array}\\] O valor esperado de \\(t\\) é: \\(E(t)= \\displaystyle\\sum_{s\\in S}t(s) p(s) = 0\\times0,0+1\\times0,3+2\\times0,4+3\\times0,3=2&lt;3=Y\\) Para obter um estimador não viciado, devemos calcular pesos adequados para as unidades amostrais. Estes requerem calcular as probabilidades de inclusão na amostra. \\[\\begin{array}{|l|c|c|c|c|}\\hline \\textrm{Rótulo da unidade}\\,\\, i &amp; 1 &amp; 2 &amp; 3 &amp; 4 \\\\\\hline \\textrm {Probabilidade de inclusão}\\,\\, \\pi_i &amp; 0,35 &amp; 0,35 &amp; 0,70 &amp; 0,60 \\\\\\hline \\textrm{Peso}\\,\\, w_i &amp; 20/7=2,857 &amp; 20/7=2,857 &amp; 10/7=1,429 &amp; 5/3=1,667 \\\\\\hline \\end{array}\\] Usando o estimador do total com os pesos adequados, obtém-se os valores das estimativas para cada amostra possível na coluna e da tabela abaixo. \\[\\begin{array}{|c|c|c|c|c|}\\hline \\textrm {Amostra} \\,\\,s &amp; \\textrm{Valores na Amostra} &amp; \\textrm {Total Amostral Ponderado}\\,\\,(\\hat Y_w) &amp; \\textrm{Probablidades} \\,\\, p(s) &amp; \\textrm {Valor do produto}\\\\\\hline 1 &amp; \\textrm{{0;0}} &amp; 0 &amp; 0,00 &amp; 0 \\\\\\hline 2 &amp; \\textrm{{0;2}} &amp; 2\\times(10/7) &amp; 0,20 &amp; 4/7\\\\\\hline 3 &amp; \\textrm{{0;1}} &amp; 1\\times(5/3) &amp; 0,15 &amp;1/4\\\\\\hline 4 &amp; \\textrm{{0;2}} &amp; 2\\times(10/7) &amp; 0,20 &amp; 4/7\\\\\\hline 5 &amp; \\textrm{{0;1}} &amp; 1\\times (5/3) &amp; 0,15 &amp; 1/4\\\\\\hline 6 &amp; \\textrm{{2;1}} &amp; 2\\times (10/7)+1\\times(5/3) &amp; 0,30 &amp; 6/7+1/2\\\\\\hline \\textrm{Total} &amp; &amp; &amp; &amp; 3\\\\\\hline \\end{array}\\] Notas O estimador \\(\\hat{Y_w}\\) tem valor esperado igual ao total populacional \\(Y\\) logo é NÃO VICIADO. O fato de que a amostra {1;2} tem probabilidade nula de ser selecionada viola os critérios definidos para que o plano de amostragem 2 seja chamado de amostragem probabilística? Sim ou não? Porquê? Temos agora duas opções para selecionar amostras (de tamanho 2) da população U, e estimar o total populacional \\(Y\\) sem vício. Qual das duas é melhor? Estratégia 1: seleção equiprovável de pares (amostras) com estimador de total ponderado (\\(\\hat{Y_w} =2t\\)) \\[\\begin{array}{|l|c|c|c|c|}\\hline \\textrm{Valores possíveis de}\\,\\, \\hat Y_w=2\\times t&amp; 0 &amp; 2 &amp; 4 &amp; 6\\\\\\hline \\textrm{Com probabilidade}\\,\\, p(s) &amp; 1/6 &amp; 2/6 &amp; 2/6 &amp; 1/6\\\\\\hline \\end{array}\\] Estratégia 2: seleção de amostras com probabilidades desiguais, e estimador de total ponderado (\\(\\hat{Y_w}\\)) \\[\\begin{array}{|l|c|c|c|c|}\\hline \\textrm{Valores possíveis de}\\,\\, \\hat Y_w &amp; 5/3 &amp; 20/7 &amp; 20/7+5/3\\\\\\hline \\textrm{Com probabilidade}\\,\\, p(s) &amp; 0,30 &amp; 0,40 &amp; 0,30 \\\\\\hline \\end{array}\\] A melhor estratégia é escolhida medindo o afastamento esperado entre o valor do estimador e o valor do total populacional desconhecido (\\(Y\\)). Para isso, usamos a variância do estimador, dada por: \\(V(\\hat Y)=\\displaystyle\\sum_{s\\in S}({\\hat Y- Y)}^2\\times p(s)\\) ou o desvio padrão do estimador, dado por \\(DP(\\hat Y)= \\sqrt {V(\\hat Y)}=\\displaystyle\\sqrt{\\sum_{s\\in S}({\\hat Y- Y)}^2\\times p(s)}\\) A seguir são calculadas as variâncias dos estimadores sob as duas estratégias (\\(E2\\) e \\(E1\\)) \\[\\begin{array}{|c|c|c|c|c|}\\hline \\textrm {Amostra} &amp; \\textrm{Valores na} &amp; \\textrm {Estimador} &amp; \\textrm{Probabilidade}\\,\\,p(s) &amp; \\textrm {Estimador} &amp; \\textrm{Probabilidade}\\,\\, p(s) \\\\ s &amp; \\textrm{Amostra} &amp; \\textrm {sob $E2$} &amp; \\textrm{sob $E2$} &amp; \\textrm{sob $E1$}&amp;\\textrm{sob $E1$} \\\\\\hline 1 &amp; \\textrm{{0;0}} &amp; 0 &amp; 0,00 &amp; 0 &amp;1/6\\\\\\hline 2 &amp; \\textrm{{0;2}} &amp; 2\\times(10/7) &amp; 0,20 &amp; 4 &amp; 1/6\\\\\\hline 3 &amp; \\textrm{{0;1}} &amp; 1\\times(5/3) &amp; 0,15 &amp; 2 &amp; 1/6\\\\\\hline 4 &amp; \\textrm{{0;2}} &amp; 2\\times(10/7) &amp; 0,20 &amp; 4 &amp; 1/6 \\\\\\hline 5 &amp; \\textrm{{0;1}} &amp; 1\\times (5/3) &amp; 0,15 &amp; 2 &amp; 1/6\\\\\\hline 6 &amp; \\textrm{{2;1}} &amp; 2\\times (10/7)+1\\times(5/3) &amp; 0,30 &amp; 6 &amp; 1/6\\\\\\hline \\textrm{Variância} &amp; \\textrm{-} &amp; 1,24 &amp; \\textrm{-} &amp; 3,67 &amp; \\textrm{-} \\\\\\hline \\end{array}\\] Conclusões: Ambas as estratégias permitem usar estimadores não viciados do total \\(Y\\). A estratégia 2 tem o estimador com menor variância, e deve ser preferida à estratégia 1, pois o tamanho das amostras é o mesmo. Minimizar a variância é o critério de desempate para escolha entre estratégias não viciadas de amostragem e estimação de igual custo total. 3.7 Teoria Básica Como já foi dito, trabalhar com a distribuição \\(p(s)\\) é complicado. Isto ocorre porque o número total \\(\\binom{N}{n}\\) de amostras possíveis cresce muito rapidamente com \\(N\\) e com \\(n\\). \\[\\begin{array}{|l|c|c|c|c|}\\hline N &amp; n &amp; \\textrm{Número de Amostras} &amp; &amp; N &amp; n &amp; \\textrm{Número de Amostras}\\\\\\hline 1.000 &amp; 2 &amp;5,00E+05&amp; &amp; 10.000 &amp; 2 &amp; 5,00E+07\\\\\\hline 1.000 &amp; 10 &amp; 2,63E+29 &amp; &amp; 10.000 &amp; 10 &amp; 2,74E+33\\\\\\hline1.000 &amp; 20 &amp;3,39E+41&amp; &amp; 10.000 &amp; 20 &amp; 4,03E+61\\\\\\hline 1.000 &amp; 100 &amp; 6,39E+139 &amp; &amp; 10.000 &amp; 100 &amp; 6,52E+247 \\\\\\hline \\end{array}\\] A saída encontrada é trabalhar com distribuições das variáveis aleatórias indicadoras \\(\\delta_1\\), \\(\\delta_2\\),… ,\\(\\delta_N\\) definidas tal que: \\(\\delta_i=I(i\\in s)=\\left\\{\\begin{array}{ll} 1 &amp; i\\in s\\\\ 0 &amp; i\\notin s\\end{array}\\right.\\,\\,\\, \\forall\\,\\, i\\in U\\). A variável \\(\\delta_i\\) é indicadora do evento ‘inclusão da unidade \\(i\\) na amostra \\(s\\)’. Exemplo 2.1 Para \\(N=4\\) e \\(n=2\\), as seis amostras possíveis podem ser representadas por: \\[\\begin{array}{|c|c|c|c|}\\hline \\textrm {Amostra} \\,\\,s &amp; \\textrm{Unidades na Amostra} &amp; \\delta_1 &amp; \\delta_2 &amp; \\delta_3 &amp; \\delta_4 \\\\\\hline 1 &amp; \\textrm{{1;2}} &amp; 1 &amp; 1 &amp; 0 &amp; 0\\\\\\hline 2 &amp; \\textrm{{1;3}} &amp; 1 &amp; 0 &amp; 1 &amp; 0\\\\\\hline 3 &amp; \\textrm{{1;4}} &amp; 1 &amp; 0 &amp; 0 &amp; 1\\\\\\hline 4 &amp; \\textrm{{2;3}} &amp; 0 &amp; 1 &amp; 1 &amp; 0 \\\\\\hline 5 &amp; \\textrm{{2;4}} &amp; 0 &amp; 1 &amp; 0 &amp; 1\\\\\\hline 6 &amp; \\textrm{{3;4}} &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\\\\\hline \\end{array}\\] Cada amostra fica univocamente determinada pelas variáveis indicadoras \\(\\delta_1\\), \\(\\delta_2\\),… ,\\(\\delta_N\\) correspondentes. As variáveis indicadoras dependem da amostra \\(s\\), apesar de não termos indicado isto explicitamente em nossa notação. Então as probabilidades de seleção ou inclusão na amostra, denotadas \\(\\pi_i\\), são definidas como: \\(\\pi_i=P({i\\in s})=\\displaystyle\\sum_{s\\ni i} p(s)=P(\\delta_i=1)=E(\\delta_i)\\, \\,\\,\\,\\forall\\,\\, i\\in U\\). As probabilidades de inclusão \\(\\pi_i\\) são ditas de primeira ordem. Precisaremos também definir as probabilidades de inclusão de segunda ordem, denotadas \\(\\pi_{ij}\\), dadas por: \\(\\pi_{ij}=P({i,j\\in s})=\\displaystyle\\sum_{s\\ni i,j} p(s)=P(\\delta_i\\delta_j=1)=E(\\delta_i\\delta_j)\\, \\,\\,\\,\\forall\\,\\, i,j\\in U\\). Note que quando \\(i=j\\), \\(\\pi_{ij}=\\pi_{ii}=\\pi_i\\, \\,\\,\\,\\forall\\,\\, i,j\\in U\\). Logo: \\(V(\\delta_i)=\\pi_i(1-\\pi_i)\\) \\(COV(\\delta_i,\\delta_j)=\\pi_{ij}-\\pi_i\\pi_j\\). Um Método Geral de Prova em Amostragem Este método se baseia nas variáveis indicadoras \\(\\delta_1\\), \\(\\delta_2\\),… ,\\(\\delta_N\\). Uma propriedade importante das variáveis indicadoras é que: \\(\\displaystyle\\sum_{i\\in s}\\delta_i(s)=\\sum_{i\\in U}\\delta_i(s)\\) Segue também que \\(\\displaystyle\\sum_{i\\in s}y_i=\\sum_{i\\in s}\\delta_iy_i=\\sum_{i\\in U}\\delta_iy_i\\) Note que o truque é converter a soma amostral em uma soma na população. Seja \\(Y=\\displaystyle\\sum_{i\\in U}y_i\\quad\\) (total populacional) o parâmetro alvo. 3.7.1 Estimador linear de total Um estimador linear de Y é sempre da forma: \\(\\hat Y_w=\\displaystyle\\sum_{i\\in s}w_iy_i=\\sum_{i\\in U}w_i\\delta_iy_i\\) onde \\(w_i\\) é o peso da unidade \\(i\\). Para que o estimador linear de \\(Y\\) seja não viciado, é preciso que: \\(E(\\hat Y_w)=Y \\Leftrightarrow \\displaystyle\\sum_{i\\in U}w_iE(\\delta_i)y_i=\\sum_{i\\in U}y_i\\Leftrightarrow\\displaystyle\\sum_{i\\in U}w_i\\pi_iy_i=\\sum_{i\\in U}y_i\\) Esta relação só será válida para quaisquer valores populacionais \\(y_i\\) da variável de pesquisa caso \\(w_i*\\pi_i=1 \\,\\,\\,\\forall\\,\\, i\\in U\\). Portanto a condição para que o estimador de total \\(\\hat Y_w=\\displaystyle\\sum_{i\\in s}w_iy_i\\) seja SEMPRE não viciado é que os pesos das unidades na amostra sejam iguais ao inverso das respectivas probabilidades de inclusão: \\(w_i={\\pi_i}^{-1}=\\frac{1}{\\pi_i}\\,\\,\\,\\forall\\,\\, i\\in U\\). Logo o estimador não viciado de total fica dado por: \\(\\hat Y_w=\\displaystyle\\sum_{i\\in s}\\frac{y_i}{\\pi_i}=\\sum_{i\\in s}{\\pi_i}^{-1}y_i=\\hat Y_{HT}\\Rightarrow\\quad\\)Estimador de Horvitz-Thompson. Este estimador está definido para qualquer plano amostral, desde que \\(\\pi_i&gt;0\\,\\,\\,\\forall\\,\\, i\\in U\\). Por isto esta é uma condição necessária para a amostragem probabilística de populações finitas. 3.7.2 Propriedades do Estimador de Horvitz-Thompson O estimador de Horvitz-Thompson é não viciado para estimar o total, ou seja, \\(E(\\hat Y_{HT})=Y\\) Prova: \\(E(\\hat Y_{HT})= E\\left[\\displaystyle\\sum_{i\\in U}\\frac{\\delta_iy_i}{\\pi_i}\\right]= \\displaystyle\\sum_{i\\in U}\\left[\\frac{E(\\delta_i)y_i}{\\pi_i}\\right]=\\sum_{i\\in U}y_i=Y\\) Esta propriedade vale para qualquer população, variável de interesse \\(y\\) e plano amostral, desde que \\(\\pi_i&gt;0\\,\\,\\,\\forall\\,\\, i\\in U\\). Variância do Estimador Horvitz-Thompson para o total \\(V(\\hat Y_{HT})= \\displaystyle\\sum_{i\\in U}\\pi_i(1-\\pi_i)\\left(\\frac{y_i}{\\pi_i}\\right)^2+\\displaystyle \\sum_{i\\in U}\\sum_{i\\neq j}(\\pi_{ij}-\\pi_i\\pi_j)\\left(\\frac{y_i}{\\pi_i}\\frac{y_j}{\\pi_j}\\right)\\) Esta é a chamada forma de Horvitz-Thompson da variância. Existe uma outra forma para esta variância, que vamos conhecer mais tarde. Prova: \\(\\begin{align}V(\\hat Y_{HT}) &amp;= V\\left[\\displaystyle\\sum_{i\\in U}\\left(\\frac{y_i}{\\pi_i}\\right)\\delta_i\\right]\\\\ &amp; =\\displaystyle\\sum_{i\\in U}\\left(\\frac{y_i}{\\pi_i}\\right)^2V(\\delta_i)+\\displaystyle \\sum_{i\\in U}\\sum_{i\\neq j}\\left(\\frac{y_i}{\\pi_i}\\frac{y_j}{\\pi_j}\\right)COV(\\delta_i,\\delta_j)\\\\ &amp; =\\displaystyle\\sum_{i\\in U}\\pi_i(1-\\pi_i)\\left(\\frac{y_i}{\\pi_i}\\right)^2+\\displaystyle \\sum_{i\\in U}\\sum_{i\\neq j}(\\pi_{ij}-\\pi_i\\pi_j)\\left(\\frac{y_i}{\\pi_i}\\frac{y_j}{\\pi_j}\\right)\\end{align}\\) Estimador da Variância do Estimador de Total Um estimador não viciado da variância do estimador de Horvitz-Thompson do total é dado por: \\(\\hat V_1(\\hat Y_{HT})= \\displaystyle\\sum_{i\\in s}\\frac{\\pi_i(1-\\pi_i)}{\\pi_i}\\left(\\frac{y_i}{\\pi_i}\\right)^2+\\displaystyle \\sum_{i\\in s}\\sum_{i\\neq j}\\frac{(\\pi_{ij}-\\pi_i\\pi_j)}{\\pi_i}\\left(\\frac{y_i}{\\pi_i}\\frac{y_j}{\\pi_j}\\right)\\) Este estimador de variância usou estimadores tipo Horvitz-Thompson dos totais nas duas parcelas da expressão da variância \\(V_p(\\hat Y_{HT})\\). Uma Forma Alternativa para a Variância Para planos amostrais de tamanho pré-fixado, pode-se demonstrar que uma forma equivalente da variância do estimador de Horvitz-Thompson é dada pela expressão de Sen-Yates-Grundy a seguir. \\(V(\\hat Y_{HT})=\\displaystyle\\sum_{i\\in U}\\sum_{j&gt;i}(\\pi_i \\pi_j-\\pi_{ij})\\left(\\frac{y_i}{\\pi_i}\\frac{y_j}{\\pi_j}\\right)^2\\) Note a troca do sinal da diferença de probabilidades de inclusão em relação à fórmula anterior. Outro Estimador da Variância do Estimador de Total \\(\\hat V_{SYG}(\\hat Y_{HT})= \\displaystyle\\sum_{i\\in s}\\sum_{j&gt;i}(\\pi_i \\pi_j-\\pi_{ij})\\left(\\frac{y_i}{\\pi_i}\\frac{y_j}{\\pi_j}\\right)^2\\). O estimador \\(\\hat V_{SYG}(\\hat Y_{HT})\\) foi obtido / motivado a partir da forma de Sen-Yates-Grundy para a variância do estimador de total. Tal estimador não coincide com o estimador de variância derivado a partir da expressão de Horvitz-Thompson. Notas Pode-se derivar estimadores de total e da variância do estimador de total como casos especiais para distintos planos amostrais. Há fórmulas de variância disponíveis para permitir avaliar qualidade do estimador de total sob distintas situações (população, variável e plano amostral). Um total populacional sempre pode ser estimado sem vício por uma soma amostral \\(\\pi\\)-ponderada. XXX Sobras XXX Chamando de \\(i\\) a unidade efetivamente selecionada após a realização de experiência aleatória e representando por \\(Y_i\\) o valor da variável \\(y\\) observado para essa unidade, nota-se que \\(Y_i\\) é uma variável aleatória que pode assumir valores no conjunto \\(Y_U=\\{y_1, y_2, \\dots, y_N\\}\\). No que se segue, \\(y_i\\) estará sempre associado à seleção de uma amostra, que é uma experiência aleatória. "]
]
